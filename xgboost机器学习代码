# 安装并加载必要的包
library(dplyr)
library(data.table)
library(xgboost)
library(Matrix)
library(caret)
library(pROC)
library(ggplot2)
library(ggpubr)
library(ggprism)

# 读取数据,这里你可以自己准备好数据格式，我这里是提取了lasso回归筛选到的6个基因以及label值，命名为data，后面直接跑代码就可以了#
data <- extracted_tpms_log2_with_labels
#提取我们所需要的y和x
selected_columns <- c("TOP2A", "CDK2", "MMP9", "SCD", "SLC2A1", "CDK1", "label")
data <- data[, selected_columns]


# 分割数据为训练集和测试集
set.seed(123)  # 设置随机种子，保证结果可复现
split <- createDataPartition(data$label, p = 0.6, list = FALSE)  # 将数据按照指定比例分割
train_data <- data[split, ]  # 训练集
test_data <- data[-split, ]  # 测试集

# 定义训练集特征和目标变量
X_train <- train_data[, -which(names(train_data) == "label")]
y_train <- train_data$label

# 将特征和目标变量转换为DMatrix格式
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)

# 设置XGBoost参数
params <- list(objective = "binary:logistic", eval_metric = "logloss", eta = 0.1, max_depth = 3)

# 设置迭代轮数（树的数量）
nrounds <- 100

# 训练XGBoost模型
xgb_model <- xgboost(params = params, data = dtrain, nrounds = nrounds)

# 在训练集上进行预测
train_predictions <- predict(xgb_model, newdata = dtrain)
train_predictions <- ifelse(train_predictions > 0.5, 1, 0)

# 计算准确率
accuracy <- mean(train_predictions == y_train)
print(paste("训练集准确率:", accuracy))

# 在测试集上进行预测
X_test <- test_data[, -which(names(test_data) == "label")]
y_test <- test_data$label

dtest <- xgb.DMatrix(data = as.matrix(X_test))
test_predictions <- predict(xgb_model, newdata = dtest)
test_predictions <- ifelse(test_predictions > 0.5, 1, 0)

# 计算准确率
accuracy <- mean(test_predictions == y_test)
print(paste("测试集准确率:", accuracy))

# 使用caret包进行调参
ctrl <- trainControl(method = "cv", number = 5, verboseIter = FALSE)

# 设置参数网格
param_grid <- expand.grid(
  nrounds = c(100, 200), 
  max_depth = c(3, 6), 
  eta = c(0.1), 
  gamma = c(0, 0.1), 
  colsample_bytree = c(0.8), 
  min_child_weight = c(1, 3), 
  subsample = c(0.8)
)

# 使用train()函数进行参数调优
xgb_model <- train(
  x = X_train,
  y = y_train,
  method = "xgbTree",
  trControl = ctrl,
  tuneGrid = param_grid
)

# 输出最佳参数配置
print(xgb_model$bestTune)

# 使用最佳参数训练模型
params <- list(objective = "binary:logistic", eval_metric = "logloss", 
               eta = 0.1, max_depth = 3, gamma = 0.1,
               colsample_bytree = 0.8,
               min_child_weight = 1,
               subsample = 0.8)

xgb_model_final <- xgb.train(params = params, data = dtrain, nrounds = 200)

# 在训练集上进行预测
train_predictions <- predict(xgb_model_final, newdata = dtrain)
train_predictions <- ifelse(train_predictions > 0.5, 1, 0)

# 计算准确率
accuracy <- mean(train_predictions == y_train)
print(paste("训练集准确率:", accuracy))

# 在测试集上进行预测
test_predictions <- predict(xgb_model_final, newdata = dtest)
test_predictions <- ifelse(test_predictions > 0.5, 1, 0)

# 计算准确率
accuracy <- mean(test_predictions == y_test)
print(paste("测试集准确率:", accuracy))

# 绘制ROC曲线
roc_obj <- roc(y_test, test_predictions)
plot(roc_obj, main = "ROC Curve", xlab = "False Positive Rate", ylab = "True Positive Rate")
abline(a = 0, b = 1, lty = 2, col = "gray")

# 创建混淆矩阵并计算性能指标
confusion_matrix <- confusionMatrix(as.factor(test_predictions), as.factor(y_test))
print(confusion_matrix)

# 提取准确率、召回率、特异性和F1分数
accuracy <- confusion_matrix$overall["Accuracy"]
recall <- confusion_matrix$byClass["Recall"]
specificity <- confusion_matrix$byClass["Specificity"]
f1 <- confusion_matrix$byClass["F1"]

cat("准确率:", accuracy, "\n")
cat("召回率:", recall, "\n")
cat("特异性:", specificity, "\n")
cat("F1分数:", f1, "\n")

#SHAP#
# 加载shapviz包
if (!require(shapviz)) install.packages('shapviz')
library(shapviz)

# 转换数据格式
X_train_matrix <- as.matrix(X_train)
X_test_matrix <- as.matrix(X_test)

# 计算SHAP值
shap_values <- shapviz(xgb_model_final, X_train_matrix)

# 绘制SHAP值图
importance_plot <- sv_importance(shap_values) +
  theme_minimal() +
  ggtitle("Feature Importance") +
  xlab("Mean Absolute SHAP Value") +
  ylab("Feature") +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        panel.grid.major.y = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(colour = "black"))

print(importance_plot)

# 可视化其他SHAP图
sv_importance(shap_values, kind = "beeswarm")
sv_waterfall(shap_values, row_id = 1)
sv_force(shap_values, row_id = 1)

